\documentclass[12pt]{article}
\usepackage[T1]{fontenc}
\usepackage[T1]{polski}
\usepackage[cp1250]{inputenc}
\newcommand{\BibTeX}{{\sc Bib}\TeX} 
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage[left=1.5cm, right=2cm]{geometry}
\setlength{\textheight}{21cm}

\title{{\bf Zadanie nr 1 - klasyfikacja wzorców}\linebreak
Analiza danych z³o¿onych z detekcj¹ wyj¹tków}
\author{Karol Kazusek - 254189, Sebastian Zych - 254264}
\date{14.10.2024}

\begin{document}
\clearpage\maketitle
\thispagestyle{empty}
\newpage
\setcounter{page}{1}
\section{Cel zadania}
Zadanie polega³o na przeprowadzeniu analiz porównawczych klasyfikacji \\
wzorców (w³asnych, wyj¹tkowych) w strumieniach danych. Do analiz nale¿a³o wybraæ tematykê
medycyny lub rozpoznawania faz ruchu aktywnoœci cz³owieka (systemy HAR)

\section{Opis zaproponowanych Klasyfikatorów}
Klasyfikatory to algorytmy stosowane w \textit{uczeniu maszynowym}, których celem jest przypisanie danych wejœciowych do jednej z wczeœniej zdefiniowanych kategorii (klas). Klasyfikacja sk³ada siê z dwóch g³ównych etapów: \textbf{trenowania} i \textbf{predykcji}. 

\begin{itemize}
    \item \textbf{Trenowanie} polega na dostarczeniu algorytmowi zbioru danych treningowych, na podstawie którego algorytm uczy siê rozpoznawaæ wzorce i ró¿nicowaæ miêdzy klasami.
    \item \textbf{Predykcja} to proces, w którym przetrenowany model jest wykorzystywany do klasyfikowania nowych, wczeœniej niewidzianych danych.
\end{itemize}

Skutecznoœæ klasyfikatorów ocenia siê przy u¿yciu ró¿nych miar, takich jak:

\begin{itemize}
    \item \textbf{Dok³adnoœæ} (accuracy) — odsetek poprawnie sklasyfikowanych przypadków,
    \item \textbf{Precyzja} (precision) — odsetek prawdziwych pozytywnych wyników spoœród wszystkich przyk³adów sklasyfikowanych jako pozytywne,
    \item \textbf{Czu³oœæ} (recall) — odsetek prawdziwie pozytywnych wyników spoœród wszystkich pozytywnych przypadków w rzeczywistoœci,
    \item \textbf{Specyficznoœæ} (specificity) — odsetek prawdziwych negatywnych wyników spoœród wszystkich przypadków rzeczywiœcie negatywnych. Mierzy zdolnoœæ klasyfikatora do prawid³owego rozpoznawania negatywnych przyk³adów, co jest szczególnie istotne w przypadku, gdy negatywna klasa jest dominuj¹ca.
\end{itemize}

Klasyfikatory znajduj¹ zastosowanie w wielu dziedzinach, takich jak medycyna, rozpoznawanie obrazów, analiza tekstu oraz inne zadania zwi¹zane z przetwarzaniem danych.

\subsection{Metody klasyfikacyjne}

\subsubsection{K-nn}

Metoda \textbf{K-Najbli¿szych S¹siadów (K-NN)} to jedna z najprostszych technik klasyfikacji. Dzia³a na zasadzie porównywania nowego punktu danych z istniej¹cymi przyk³adami treningowymi. Algorytm wybiera \( K \) najbli¿szych s¹siadów (na podstawie odleg³oœci euklidesowej lub innych miar), a nastêpnie przypisuje nowy punkt do klasy, która wystêpuje najczêœciej wœród tych s¹siadów.

\begin{itemize}
    \item \texttt{n\_neighbors}: Liczba s¹siadów (\( K \)) do uwzglêdnienia przy klasyfikacji.
    \item \texttt{weights}: Sposób wa¿enia s¹siadów. Mo¿liwe wartoœci to \texttt{'uniform'} (wszyscy s¹siedzi maj¹ tak¹ sam¹ wagê) i \texttt{'distance'} (bli¿si s¹siedzi maj¹ wiêkszy wp³yw).
    \item \texttt{metric}: Miara odleg³oœci u¿ywana do porównania punktów,która w zale¿noœci od parametru mo¿e reprezentowaæ odleg³oœæ euklidesow¹ lub Manhattan.
\end{itemize}

\subsubsection{Klasyfikator baysowski}
\textbf{Klasyfikacja Bayesowska} opiera siê na \textit{twierdzeniu Bayesa}, które opisuje zale¿noœæ miêdzy prawdopodobieñstwem wyst¹pienia klasy a dostarczonymi danymi. W najprostszym przypadku, \textbf{naiwny klasyfikator Bayesa} zak³ada, ¿e cechy s¹ niezale¿ne od siebie. Model wylicza prawdopodobieñstwo ka¿dej klasy na podstawie danych wejœciowych, a nastêpnie przypisuje nowy przyk³ad do klasy o najwiêkszym prawdopodobieñstwie.

\begin{itemize}
    \item \texttt{var\_smoothing}: Parametr ten reguluje wielkoœæ wyg³adzania (dodanie ma³ej sta³ej do wariancji, aby unikn¹æ dzielenia przez zero). (Wyg³adzanie Laplace).
\end{itemize}

\subsubsection{Drzewa decyzyjne}
\textbf{Drzewa decyzyjne} to metoda klasyfikacji oparta na strukturze drzewa, gdzie ka¿dy wêze³ reprezentuje decyzjê na podstawie jednej cechy, a ka¿da ga³¹Ÿ odpowiada wynikom tej decyzji. Proces ten powtarza siê rekurencyjnie, a¿ do osi¹gniêcia koñcowych wêz³ów liœciowych, które reprezentuj¹ klasy.

\begin{itemize}
    \item \texttt{criterion}: Funkcja oceny podzia³u. Mo¿liwe wartoœci to \texttt{'gini'} (wspó³czynnik Giniego) i \texttt{'entropy'} (entropia).
    \item \texttt{max\_depth}: Maksymalna g³êbokoœæ drzewa. Ograniczenie g³êbokoœci mo¿e zapobiec nadmiernemu dopasowaniu (overfitting).
    \item \texttt{min\_samples\_split}: Minimalna liczba próbek potrzebna do podzia³u w wêŸle.
    \item \texttt{min\_samples\_leaf}: Minimalna liczba próbek w liœciu. Pozwala na kontrolê wielkoœci koñcowych wêz³ów.
    \item \texttt{max\_features}: Maksymalna liczba cech brana pod uwagê przy ka¿dym podziale. Mo¿e to byæ liczba ca³kowita, wartoœæ zmiennoprzecinkowa lub \texttt{'auto'}, \texttt{'sqrt'}, \texttt{'log2'}.
\end{itemize}

\subsubsection{Lasy losowe}

\textbf{Lasy losowe} to technika zespo³owa oparta na wielu drzewach decyzyjnych. Ka¿de drzewo jest trenowane na losowym podzbiorze danych oraz cech. Wyniki klasyfikacji uzyskuje siê poprzez g³osowanie wiêkszoœciowe wœród wszystkich drzew. Lasy losowe zmniejszaj¹ problem nadmiernego dopasowania, który jest powszechny w pojedynczych drzewach decyzyjnych.

\begin{itemize}
    \item \texttt{n\_estimators}: Liczba drzew decyzyjnych w lesie. Wiêksza liczba drzew zwiêksza stabilnoœæ predykcji.
    \item \texttt{criterion}: Kryterium oceny podzia³u, takie jak \texttt{'gini'} lub \texttt{'entropy'}, podobnie jak w przypadku drzew decyzyjnych.
    \item \texttt{max\_features}: Maksymalna liczba cech brana pod uwagê przy ka¿dym podziale.
    \item \texttt{bootstrap}: Jeœli \texttt{True}, to próbki s¹ losowane z zamian¹ (bootstrap). Jeœli \texttt{False}, nie jest stosowana zamiana.
    \item \texttt{max\_depth}, \texttt{min\_samples\_split}, \texttt{min\_samples\_leaf}: Parametry te dzia³aj¹ podobnie jak w przypadku pojedynczych drzew decyzyjnych.
\end{itemize}

\subsubsection{SVM}
\textbf{Maszyny wektorów noœnych (SVM)} to metoda klasyfikacji, która stara siê znaleŸæ optymaln¹ hiperp³aszczyznê, która maksymalnie rozdziela dane pomiêdzy dwie klasy. SVM mo¿e dzia³aæ zarówno liniowo, jak i nieliniowo, dziêki zastosowaniu tzw. \textit{j¹der} (kernels), które przekszta³caj¹ dane na wy¿sze wymiary, aby umo¿liwiæ rozdzielenie nieliniowych danych.

\begin{itemize}
    \item \texttt{C}: Parametr regularizacji. Wy¿sza wartoœæ \( C \) sprawia, ¿e model bardziej dopasowuje siê do danych treningowych, ale mo¿e prowadziæ do nadmiernego dopasowania.
    \item \texttt{kernel}: Funkcja j¹drowa do przekszta³cania danych. Mo¿liwe wartoœci to \texttt{'linear'}, \texttt{'poly'} (wielomianowa), \texttt{'rbf'} (j¹dro radialne) i \texttt{'sigmoid'}.
    \item \texttt{gamma}: Parametr j¹dra, który kontroluje zakres wp³ywu pojedynczego przyk³adu treningowego. Mo¿e byæ ustawiony na \texttt{'scale'} lub \texttt{'auto'}.
    \item \texttt{probability}: Jeœli \texttt{True}, to model bêdzie zwraca³ prawdopodobieñstwa klas, co wymaga dodatkowego obliczenia.
\end{itemize}
\subsubsection{Perceptron Wielowarstwowy (MLP)}
\textbf{Perceptron wielowarstwowy (MLP)} to algorytm uczenia g³êbokiego bazuj¹cy na sztucznych sieciach neuronowych. To jedna z najprostszych form sieci neuronowych, bêd¹ca modelem uczenia nadzorowanego. Jego struktura sk³ada siê z trzech g³ównych warstw: warstwy wejœciowej, jednej lub wiêcej warstw ukrytych oraz warstwy wyjœciowej. Ka¿da warstwa sk³ada siê z neuronów, które s¹ podstawowymi jednostkami przetwarzaj¹cymi dane.

\begin{itemize}
    \item \texttt{hidden\_layer\_sizes}: Liczba neuronów w ka¿dej warstwie ukrytej. Mo¿na podaæ jedn¹ wartoœæ (liczba neuronów w jednej warstwie) lub krotkê definiuj¹c¹ liczbê neuronów w kilku warstwach. Domyœlnie: (100,).
    \item \texttt{activation}: Funkcja aktywacji dla neuronów. Mo¿liwe wartoœci to \texttt{'identity'}, \texttt{'logistic'}, \texttt{'tanh'} i \texttt{'relu'}.
    \item \texttt{solver}: Algorytm u¿ywany do optymalizacji. Mo¿liwe wartoœci to \texttt{'lbfgs'} (optymalizacja metod¹ quasi-Newtona), \texttt{'sgd'} (stochastyczny gradient prosty) i \texttt{'adam'} (optymalizacja adaptacyjna).
    \item \texttt{alpha}: Parametr regularyzacji \( L_2 \), który zapobiega nadmiernemu dopasowaniu.
    \item \texttt{learning\_rate}: Szybkoœæ uczenia. Mo¿liwe wartoœci to \texttt{'constant'}, \texttt{'invscaling'} oraz \texttt{'adaptive'}.
    \item \texttt{max\_iter}: Maksymalna liczba iteracji podczas treningu.
\end{itemize}

\section{Charakterystyka wybranych do danych}

\href{https://www.physionet.org/content/mitdb/1.0.0/}{MIT-BIH Arrhythmia Database} to szeroko stosowany zestaw danych wykorzystywany w badaniach dotycz¹cych analizy sygna³ów elektrokardiograficznych (EKG) oraz automatycznej klasyfikacji arytmii. Zbiór ten zawiera 48 zapisów sygna³ów EKG zarejestrowanych u 47 pacjentów, w tym zarówno osób z ró¿nymi typami arytmii, jak i zdrowych. Ka¿dy zapis obejmuje oko³o 30 minut sygna³u EKG, który zosta³ pobrany w czêstotliwoœci 125 Hz.

Dane zosta³y rêcznie oznakowane przez kardiologów, co pozwala na identyfikacjê ró¿nych typów arytmii, takich jak np. skurcze dodatkowe, migotanie przedsionków czy blokady serca. MIT-BIH Arrhythmia Database jest czêsto wykorzystywany w algorytmach sztucznej inteligencji do trenowania systemów do automatycznej diagnozy arytmii. 
\\
Kroki u¿ywane do ekstrakcji uderzeñ z sygna³u EKG wed³ug autorów \cite{DBLP:journals/corr/abs-1805-0079DBLP:journals/corr/abs-1805-007944} by³y nastêpuj¹ce:
\begin{enumerate}
    \item Podzia³ ci¹g³ego sygna³u EKG na okna 10s i wybór jednego okna 10s z sygna³u EKG.
    \item Normalizacja wartoœci amplitudy do zakresu od zera do jeden.
    \item Znalezienie zbioru wszystkich lokalnych maksimów na podstawie zerokrosów pierwszej pochodnej.
    \item Znalezienie zbioru kandydatów na szczyty R EKG poprzez zastosowanie progu 0.9 na znormalizowanej wartoœci lokalnych maksimów.
    \item Znalezienie mediany interwa³ów czasowych R-R jako nominalnego okresu bicia serca dla danego okna (T).
    \item Dla ka¿dego szczytu R wybór czêœci sygna³u o d³ugoœci równej 1.2T.
    \item Uzupe³nienie ka¿dej wybranej czêœci zerami, aby jej d³ugoœæ by³a równa zdefiniowanej sta³ej d³ugoœci.
\end{enumerate}

\textbf{Liczba próbek}: 21900  \\
\textbf{Liczba kategorii}: 5 \\
\textbf{Czêstotliwoœæ próbkowania}: 125Hz \\
\begin{tabular}{lcc}
    \textbf{Nazwa klasy} & \textbf{etykieta} & \textbf{liczebnoœæ} \\
    \hline\hline\\[-0.4cm]
    Normalne uderzenie &  0 & 1658 \\ \hline
    Przedwczesne uderzenie nadkomorowe &  1 &  556\\ 
    Przedwczesny skurcz komorowy &  2 & 1448\\ 
    Fuzja skurczu komorowego i normalnego uderzenia &  3 & 162\\ 
    Niezdyscyplinowane uderzenie &  4 & 1608\\ 
\end{tabular}


\section{Eksperymenty i wyniki}

\subsection{Eksperyment nr 1}
\subsubsection{Za³o¿enia}
Wykonanie porównania dla minimum dwóch klasyfikatorów.
Wybrane klasyfikatory to K-nn oraz RF. 
Dla uproszczenia i oszczedzenia czasu nastêpne graficzne oceny klasyfikatora bêd¹ wzglêdem najlepszego z Tabeli 1 i 2 odpowiednio dla K-nn i RF.

\subsubsection{Rezultat K-nn}
\begin{table}[htbp]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Classifier} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Sensitivity} & \textbf{Specificity} \\ \hline
KNeighborsClassifier\_metric=e\_n=3  & 0.929492 & 0.900287 & 0.884546 & 0.981032 \\ \hline
KNeighborsClassifier\_metric=e\_n=5  & 0.929308 & 0.902272 & 0.881949 & 0.980992 \\ \hline
KNeighborsClassifier\_metric=e\_n=7  & 0.924521 & 0.899514 & 0.876439 & 0.979617 \\ \hline
KNeighborsClassifier\_metric=m\_n=3  & 0.937960 & 0.911232 & 0.893256 & 0.983386 \\ \hline
KNeighborsClassifier\_metric=m\_n=5  & 0.934094 & 0.904677 & 0.881621 & 0.982366 \\ \hline
KNeighborsClassifier\_metric=m\_n=7  & 0.929124 & 0.901620 & 0.876057 & 0.980939 \\ \hline
\end{tabular}
\caption{Statystki K-nn z ró¿nymi metrykami dystansu i liczb¹ s¹siadów}
\label{tab:knn_performance}
\end{table}


\begin{figure}[hp!]
    \centering
    \includegraphics[width=12.3cm]{Knn1.png}
    \vspace{-0.1cm}
    \caption{Krzywa uczenia dla K-nn}
    \label{Krzywa uczenia dla K-nn}
\end{figure}
\begin{figure}[hp!]
    \centering
    \includegraphics[width=15.3cm]{Knn2.png}
    \vspace{-0.1cm}
    \caption{Krzywe AUROC dla K-nn}
    \label{Krzywe AUROC dla K-nn}
\end{figure}
\begin{figure}[hp!]
    \centering
    \includegraphics[width=12.3cm]{Knn3.png}
    \vspace{-0.1cm}
    \caption{Macierz pomy³ek dla K-nn}
    \label{Macierz pomy³ek dla K-nn}
\end{figure}
\newpage
\subsubsection{Rezultat RF}
    \begin{table}[htbp]
        \centering
        \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Classifier} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Sensitivity} & \textbf{Specificity} \\ \hline
        RF\_d=10\_f=log2\_l=1\_s=2\_n=50  & 0.901694 & 0.903927 & 0.810468 & 0.972396 \\ \hline
        RF\_d=10\_f=log2\_l=1\_s=10\_n=50 & 0.899485 & 0.905113 & 0.806056 & 0.971709 \\ \hline
        RF\_d=10\_f=log2\_l=5\_s=2\_n=50  & 0.903903 & 0.915494 & 0.813242 & 0.972906 \\ \hline
        RF\_d=10\_f=log2\_l=5\_s=10\_n=50 & 0.899853 & 0.905611 & 0.805944 & 0.971839 \\ \hline
        RF\_d=20\_f=log2\_l=1\_s=2\_n=50  & 0.930781 & 0.927284 & 0.868739 & 0.980685 \\ \hline
        RF\_d=20\_f=log2\_l=1\_s=10\_n=50 & 0.929492 & 0.928302 & 0.857599 & 0.980289 \\ \hline
        RF\_d=20\_f=log2\_l=5\_s=2\_n=50  & 0.925074 & 0.925280 & 0.851705 & 0.979075 \\ \hline
        RF\_d=20\_f=log2\_l=5\_s=10\_n=50 & 0.927651 & 0.925083 & 0.857425 & 0.979810 \\ \hline
        \end{tabular}
        \caption{Statystki RF z ró¿nymi metrykami}
        \label{tab:rf_performance}
    \end{table}

\begin{figure}[hp!]
    \centering
    \includegraphics[width=12.3cm]{RF1.png}
    \vspace{-0.1cm}
    \caption{Krzywa uczenia dla RF}
    \label{Krzywa uczenia dla RF}
\end{figure}
\begin{figure}[hp!]
    \centering
    \includegraphics[width=15.3cm]{RF2.png}
    \vspace{-0.1cm}
    \caption{Krzywe AUROC dla RF}
    \label{Krzywe AUROC dla RF}
\end{figure}
\begin{figure}[htbp!]
    \centering
    \includegraphics[width=12.3cm]{RF3.png}
    \vspace{-0.1cm}
    \caption{Macierz pomy³ek dla RF}
    \label{Macierz pomy³ek dla RF}
\end{figure}
\newpage
\subsection{Eksperyment nr 2}
Zaproponowanie 3 klasyfikatorów zespo³owych i porównianie ich efektywnoœci.
Wybrane klasyfikatory zespo³owe to:.
\begin{itemize}
    \item K-nn + RF + NB
    \item K-nn + RF + DT
    \item DT + SVC + MLP 
\end{itemize} 

\subsubsection{Rezultat K-nn + RF + DT}
\begin{table}[htbp]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Classifier} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Sensitivity} & \textbf{Specificity} \\ \hline
VotingClassifier & 0.938144 & 0.912708 & 0.892787 & 0.983395 \\ \hline
\end{tabular}
\caption{Statystki K-nn + RF + DT}
\label{tab:voting_performance}
\end{table}
\begin{figure}[hp!]
    \centering
    \includegraphics[width=12.3cm]{KNN+DT+RF1.png}
    \vspace{-0.1cm}
    \caption{Krzywa uczenia dla KNN+DT+RF}
    \label{Krzywa uczenia dla KNN+DT+RF}
\end{figure}
\begin{figure}[hp!]
    \centering
    \includegraphics[width=15.3cm]{KNN+DT+RF2.png}
    \vspace{-0.1cm}
    \caption{Krzywe AUROC dla KNN+DT+RF}
    \label{Krzywe AUROC dla KNN+DT+RF}
\end{figure}
\begin{figure}[htbp!]
    \centering
    \includegraphics[width=12.3cm]{KNN+DT+RF3.png}
    \vspace{-0.1cm}
    \caption{Macierz pomy³ek dla KNN+DT+RF}
    \label{Macierz pomy³ek dla KNN+DT+RF}
\end{figure}
\newpage
\subsubsection{Rezultat K-nn + RF + NB}
\begin{table}[htbp]
    \centering
    \begin{tabular}{|l|c|c|c|c|}
    \hline
    \textbf{Classifier} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Sensitivity} & \textbf{Specificity} \\ \hline
    VotingClassifier & 0.928019 & 0.888637 & 0.890537 & 0.980738 \\ \hline
    \end{tabular}
    \caption{Statystki dla KNN+RF+NB}
    \label{tab:voting_performance}
    \end{table}
\begin{figure}[hp!]
    \centering
    \includegraphics[width=12.3cm]{KNN+RF+NB1.png}
    \vspace{-0.1cm}
    \caption{Krzywa uczenia dla KNN+RF+NB}
    \label{Krzywa uczenia dla KNN+RF+NB}
\end{figure}
\begin{figure}[hp!]
    \centering
    \includegraphics[width=15.3cm]{KNN+RF+NB2.png}
    \vspace{-0.1cm}
    \caption{Krzywe AUROC dla KNN+RF+NB}
    \label{Krzywe AUROC dla KNN+RF+NB}
\end{figure}
\begin{figure}[htbp!]
    \centering
    \includegraphics[width=12.3cm]{KNN+RF+NB3.png}
    \vspace{-0.1cm}
    \caption{Macierz pomy³ek dla KNN+RF+NB}
    \label{Macierz pomy³ek dla KNN+RF+NB}
\end{figure}
\newpage
\subsubsection{Rezultat DT + SVC + MLP}
\begin{table}[htbp]
    \centering
    \begin{tabular}{|l|c|c|c|c|}
    \hline
    \textbf{Classifier} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Sensitivity} & \textbf{Specificity} \\ \hline
    VotingClassifier & 0.927651 & 0.895403 & 0.882166 & 0.980752 \\ \hline
    \end{tabular}
    \caption{Statystki dla DT + SVC + MLP}
    \label{tab:voting_performance}
    \end{table}    
\begin{figure}[hp!]
    \centering
    \includegraphics[width=12.3cm]{DT+SVC+MLP1.png}
    \vspace{-0.1cm}
    \caption{Krzywa uczenia dla DT+SVC+MLP}
    \label{Krzywa uczenia dla DT+SVC+MLP}
\end{figure}
\begin{figure}[hp!]
    \centering
    \includegraphics[width=15.3cm]{DT+SVC+MLP2.png}
    \vspace{-0.1cm}
    \caption{Krzywe AUROC dla DT+SVC+MLP}
    \label{Krzywe AUROC dla DT+SVC+MLP}
\end{figure}
\begin{figure}[htbp!]
    \centering
    \includegraphics[width=12.3cm]{DT+SVC+MLP3.png}
    \vspace{-0.1cm}
    \caption{Macierz pomy³ek dla DT+SVC+MLP}
    \label{Macierz pomy³ek dla DT+SVC+MLP}
\end{figure}
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PODROZDZIA£ PT. EKSPERYMENT NR N 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Eksperyment nr 3}
Utworzenie sieci neurownowej i wytrenowania jej w celu klasyfikacji wzorców.
Wybraliœmy sieci MLP przez jej prost¹ implementacjê, alternatyw¹ mog³a byæ sieci MADALINE.
\subsubsection{Rezultat MLP}  
\begin{table}[htbp]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Classifier} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Sensitivity} & \textbf{Specificity} \\ \hline
MLP\_h\_l\_s=[20, 20]\_a=logistic\_l\_rate=constant & 0.916237 & 0.892466 & 0.865486 & 0.977383 \\ \hline
MLP\_h\_l\_s=[20, 20]\_a=relu\_l\_rate=constant & 0.923417 & 0.882847 & 0.871027 & 0.979630 \\ \hline
MLP\_h\_l\_s=[20, 20]\_a=tanh\_l\_rate=constant & 0.921944 & 0.887618 & 0.879874 & 0.979344 \\ \hline
MLP\_h\_l\_s=[50, 50]\_a=logistic\_l\_rate=constant & 0.932806 & 0.890531 & 0.896438 & 0.982492 \\ \hline
MLP\_h\_l\_s=[50, 50]\_a=relu\_l\_rate=constant & 0.933542 & 0.888540 & 0.895065 & 0.982791 \\ \hline
MLP\_h\_l\_s=[50, 50]\_a=tanh\_l\_rate=constant & 0.932990 & 0.893440 & 0.890982 & 0.982414 \\ \hline
\end{tabular}
\caption{Statystki dla Klasyfikatora MLP z róznymi rozmiaramy warstwy ukrytych (2), funkcji aktwacji}
\label{tab:mlp_performance}
\end{table}
\begin{figure}[hp!]
    \centering
    \includegraphics[width=12.3cm]{MLP1.png}
    \vspace{-0.1cm}
    \caption{Krzywa uczenia dla MLP}
    \label{Krzywa uczenia dla MLP}
\end{figure}
\begin{figure}[hp!]
    \centering
    \includegraphics[width=15.3cm]{MLP2.png}
    \vspace{-0.1cm}
    \caption{Krzywe AUROC dla MLP}
    \label{Krzywe AUROC dla MLP}
\end{figure}
\begin{figure}[htbp!]
    \centering
    \includegraphics[width=12.3cm]{MLP3.png}
    \vspace{-0.1cm}
    \caption{Macierz pomy³ek dla MLP}
    \label{Macierz pomy³ek dla MLP}
\end{figure}

\newpage

\section{Wnioski}

Wnioski z przeprowadzonych eksperymentów dowodz¹, ¿e 

\begin{itemize}
    \item Efektywnoœæ poszczególnych klasyfikatorów w du¿ej mierze zale¿y od poprawnego wyboru jego parametrów. 
    \item W wiekszoœci przypadków klasyfikatory zespo³owe s¹ lepszê od pojedynczych klasyfikatorów, poniewa¿ poszczególne klasyfikatory posiadaj¹ zró¿nicowane silne jak i s³abe strony.
    Przez g³osowanie, s³abe strony i przez to b³êdy pojedynczych klasyfikatorów s¹ skorygowane przez g³osy innych klasyfikatorów. Dzieki czemu zyskaliœmy najlepszy klasyfikator zespo³owy K-nn + RF + NB.
    \item Ciekawym elementem do zbadania mog³o byæ prób stworzenia zespo³owego klasyfikatora sk³adaj¹cego siê z pojedynczego klasyfikatora z ró¿nymi parametrami.
    \item Sieci Neuronowa MLP uzyska³a porównywalny wynik do innych klasyfikatorów, lecz przez wysokie wymagania wydajnoœciowe nie byliœmy w stanie przetrenowaæ sieci z wszystkim mo¿liwimy parametrami, najwa¿niejszymi z nich jest iloœæ warstw i neuronów, iloœæ epok oraz sta³a uczenia.   
    \item Zbiór danych by³ zbalanosoway zwglêdem liczebnoœci klas, jednyn¹ klas¹ o bardzo ma³ej iloœci by³a Fuzja skurcz komorowego i normalnego uderzenia, przez to uzyskiwa³a najwiêkszy b³¹d klasyfikatora.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAFIA
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewcommand\refname{Bibliografia}
\bibliographystyle{plain}
\bibliography{bibliografia_wzor}

\end{document}
